---
title: "Data manipulation in R"
author: "[Andreas Kitsche](andreaskitsche@cbg.contitech.de)"
date: "16.11.2017"
output:
  ioslides_presentation:
    highlight: haddock
    theme: simple
    incremental: no
    slideNumber: yes
  beamer_presentation:
    incremental: no
    toc: yes
  revealjs::revealjs_presentation:
    highlight: haddock
    reveal_options:
      previewLinks: yes
      slideNumber: yes
    self_contained: yes
    theme: simple
    transition: slide
  slidy_presentation:
    incremental: no
subtitle: using dplyr
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, error=FALSE, message = FALSE)
```

```{r, echo = FALSE}
#library(knitcitations)
#bib <- read.bibtex("References.bib")
```

# Introduction to R (if required ;-))

# R basics
## R basics

This section sets is a reminder on the basic functionality of R. For more details the author refers to the [introductory material](). In addition we define some standards that are essential when working with R and are highly recommended by the author. 

## Data organisation
This topic describes how to organize data in spreadsheets. It is inspired by Karl Broman's excellent [data organisation guide](http://kbroman.org/dataorg/). The following list gives you some advice:

1. Data that should be analyzed together should be in one single file
2. Record your data in `flat file` format:
  * there should be one separate line for each experimental unit (plant, animal, pot, petri dish, …) 
  * rows corresponding to subjects and columns corresponding to variables
3. All columns should have (short) headers
4. Choose good names for things:  short, but meaningful
  * don’t use spaces
  * use underscores or perhaps hyphens
  * Be careful about extraneous spaces. `glucose` is different from `glucose  ` (with an extra space at the end). 
  * Avoid special characters (`#`, ``)
5. Fill in all cells. Use some common code for missing data
6. No calculations in the raw data files 
7. Don't use font color or highlighting as data 



## Writing your R code
Avoid writing your R code into the Console. Ever write your code into an edition and send the code to the Console. Save your R script with a meaningful name in an `.R` file, e.g. `data_manipulation_in_r.R`. When writing your code use a consistent style so it is easy to read. The following list gives you some advice:

### Structure of the R Script

1. include a header specifying the topic, author, and date of the script as comment lines
2. start with listing the required R packages
3. read in data
4. use short, but precise object names
5. make comments, structure the code

### Naming Conventions

1. Names should indicate use and purpose
2. File names should be descriptive
3. File names should end in `.R`
4. Variable and function names should be lowercase
5. Use an underscore (`_`) to separate words within a name
6. avoid using names of existing functions and variables


### Comments

1. Should indicate the purpose of the code
2. Should always precede code

### General Layout

1. Be consistent with indentation, two spaces is recommended
2. Define a maximum line length, 80 characters is recommended
3. Place spaces around all operators (`=`, `+`, `-`, `<-`)
4. Include spaces after commas

### General Syntax

1. Use `<-` for assignment not `=`
2. Use `TRUE` and `FALSE` rather than `T` and `F`
3. Avoid the use of `;`
4. Opening curly braces `{` should never be on their own line
5. Closing braces `}` should always be on their own line



## Importing data
### Import
R provides several function to import data sets. Within this course we will use the base R `read.table` function. If you use R Studio you can also import the data set via the *Import Dataset* bottom at the *Environment* pane.
The function `read.table` reads a file in table format and creates a data frame from it. The function `read.csv` is identical to `read.table` except for the defaults. Is is intended for reading *comma separated value* files (`.csv`). Specifying some argument will speed up the data import and control the output file, e.g.:

* `header` - a logical value indicating whether the file contains the names of the variables as its first line
* `sep` - the field separator character
* `dec` - the character used in the file for decimal points
* `col.names` - a vector of optional names for the variables
* `na.strings` - a character vector of strings which are to be interpreted as NA values
* `colClasses` - character. A vector of classes to be assumed for the columns
* `nrows` - integer: the maximum number of rows to read in
* `stringsAsFactors` - logical: should character vectors be converted to factors


### First steps
The first steps after you have imported your data set into R is to get an overview using the following functions:

```{r eval=TRUE, results='hide',echo=TRUE, cache=TRUE}
View(iris)
head(iris, n = 10)#shows the first 10 lines of the data frame
tail(iris, n = 10)#shows the last 10 lines of the data frame
str(iris)#returns the structure of the object
dim(iris)#return the dimension (number of rows and number of columns) of the data frame
names(iris)#return the names of the variables 
#check the levels of a factor variable
levels(iris$Species)
```


# Introduction - The Data Science Workflow

## The data science workflow

Tis talk focuses on tidy and tranform your data to afterwards easily visualize and model your data.

![](figures/data-science.png)

# Introduction - the tidyverse
![](figures/tidyverse_hex.png)

## Introduction - the tidyverse


```{r chunck_01, eval=TRUE, echo=TRUE, results='hide', message=TRUE}
#install.packages("tidyverse")#install the package, if nessecary
library(tidyverse)
```
Tidy code is easier to write, read, maintain and almost always faster than the base R counterparts.

## Introduction - Prerequisites

Within this talk we will use the following datasets:

```{r chunck_02, eval=TRUE, echo=TRUE, results='hide'}
?ggplot2::mpg
?datasets::iris
library(nycflights13)
?nycflights13::flights
```

## Introduction - tidy data set

> In brief, when your data is tidy, each column is a variable, and each row is an observation. Tidy data is important because the consistent structure lets you focus your struggle on questions about the data, not fighting to get the data into the right form for different functions. - Hadley Wickham

# Tibbles

## What are tibbles?

> Tibbles are data frames, but they tweak some older behaviours to make life a little easier. - Hadley Wickham

```{r chunck_03, eval=TRUE, echo=TRUE, results='markup'}
tibble(
  x = 1:5, 
  y = 1, 
  z = letters[1:5]
)
```

## What are tibbles?

`tibble()` does much less than `data.frame()`:

* it never changes the type of the inputs (e.g. it never converts strings to factors!)
* it never changes the names of variables
* it never creates row names

## What are tibbles?

```{r chunck_04, eval=TRUE, echo=TRUE, results='markup'}
test_data <- data.frame(
  x = 1:5, 
  y = 1, 
  z = letters[1:5]
)
str(test_data)
```

# Introduction to dplyr

## Introduction to dplyr
The `dplyr` package (among other things) reimplements 5 of my most common R data manipulation idioms - often, in blazing fast C++.

![](figures/dplyr.png)

## Datamanipulation in R
The basic data manipulation task in R are:

* selecting columns
* filtering rows
* ordering data
* calculating new variables from existing variables
* summarizing data sets

In addition to the base R functionality of data wrangling (e.g., `subset`, `aggregate`, `$` operator, `[]` sub-setting, ...) we introduce the package `dplyr`. So why to learn new functions when everything is fine? 

* Great for the most important data manipulation tools needed for data analysis 
* Provide blazing fast performance for in-memory data by writing key pieces in C++
* Intuitive to write and easy to read, especially when using the "chaining" syntax (covered below)
* all required data manipulation functions in one package
* Common structure (for all dplyr verbs)

You can find an exhaustive [translation table](http://www.significantdigits.org/2017/10/switching-from-base-r-to-tidyverse/) from [Rajesh Korde](http://www.significantdigits.org/).

### selecting columns
Select a subset of the columns of a data frame by names 
base R style:
```{r ase R select, eval=TRUE, results='hide'}
weather[,c("origin", "temp", "precip")]
```

`select()` function:
```{r select dplyr, eval=TRUE, results='hide', warning=FALSE, message=FALSE}
library(dplyr)
select(weather, origin, temp, precip)
select(weather, origin:temp)
select(weather, -(year:hour))
```
Select a subset of the columns of a data frame by numbers  
base R style:
```{r base R select number, eval=TRUE, results='hide'}
weather[,1:3]
```
dplyrs `select` function:
```{r select number dplyr, eval=TRUE, results='hide', warning=FALSE, message=FALSE}
select(weather, 1:3)
```

### Filter
select a subset of the rows of a data frame

base R style
```{r filder old, eval=TRUE, results='hide'}
weather[weather$origin=="EWR" | weather$month==1,]
```

`subset()` function
```{r subset, eval=TRUE, results='hide'}
subset(weather, origin=="EWR" | origin==1)
subset(weather, origin=="EWR" & month==1)
```

dplyrs `filter()` function
```{r filter new, eval=TRUE, results='hide'}
filter(weather, origin=="EWR" | origin=="JFK")
filter(weather, origin=="EWR" & month==1)
```

Select a subset of the rows of a data frame by numbers.

base R style
```{r filter numbers, eval=TRUE, results='hide'}
weather[1:10,]
```
dplyrs `slice()` function

```{r filter numbers dplyr, eval=TRUE, results='hide'}
slice(weather, 1:10)
```

### Arrange
Arrange rows by variables (reorder the rows).

Base R `order()` function

```{r base order, eval=TRUE, results='hide'}
weather[order(weather$temp, weather$precip),]
```

dplyrs `arrange()` function

```{r arrange dpylr, results='hide', eval=TRUE}
arrange(weather, temp, precip)
arrange(weather, desc(temp))#Use desc() to order a column in descending order
```



### Mutate
Add new columns that are functions of existing columns.

base R style

```{r mutate base, eval=TRUE, results='hide'}
weather$precip_to_temp <- weather$precip/weather$temp
base::transform(weather, precip_to_temp = precip/temp)
```

dplyrs `mutate()` function

```{r dplyr arrange, eval=TRUE, results='hide'}
mutate(weather, precip_to_temp = precip/temp)
```

`mutate()` allows you to refer to columns that you just created

```{r muatate multiple, results='hide', eval=TRUE}
mutate(weather, 
       precip_to_temp = precip/temp,
       precip_to_temp_10 = precip_to_temp*10)
```
Note: If you only want to keep the new variables, use `transmute()`

### Summarising data sets

base R `aggregate()` function computes summary statistics of data subsets

```{r aggregate base, eval=TRUE, results='hide'}
aggregate(weather$temp, by = list(origin = weather$origin), FUN = mean)
aggregate(temp ~ origin, data = weather, FUN = mean)#formula notation
```

dplyr `summarise()` function collapses a data frame to a single row

```{r dypyr summarise, eval=TRUE, results='hide'}
summarise(weather, mean_temp = mean(temp, na.rm=TRUE))
summarise(weather, mean_temp = mean(temp, na.rm=TRUE),
                   sd_temp   = sd(temp),
                   median_sd = median(temp))
#With data frames, you can create and immediately use summaries
summarise(weather, mean_temp = mean(temp, na.rm=TRUE),
                     sd_temp = sd(temp),
                mean_sd_temp = mean_temp/sd_temp)
```

Commonalities of `dplyr` verbs:

* The first argument is a data frame
* The subsequent arguments describe what to do with it, and you can refer to columns in the data frame directly without using `$`.
* The result is a new data frame

### Grouped operations

```{r dplyr group_by, eval=TRUE, results='hide'}
dplyr::summarise(group_by(weather, origin), max(temp))
dplyr::summarise(group_by(weather, origin), length(temp))
dplyr::summarise(group_by(weather, origin), count_origin=n())
dplyr::summarise(group_by(weather, origin, year), count_origin_year=n())
```


## Datamanipulation workflow

## The pipe operator

![](figures/pipe.png)

### Chaining or Pipelining

Usual way to perform multiple operations

Save objects :

```{r save style, eval=TRUE, results='hide'}
Data_1 <- filter(weather, origin=="EWR", year==2013, between(precip, 0.05, Inf))
Data_2 <- select(Data_1,  origin:temp)
Data_3 <- mutate(Data_2, temp_square = temp^2)
Data_4 <- group_by(Data_3, origin, month)
Data_5 <- summarise(Data_4, min(temp_square))
Data_5
```

Nesting operations: Hard to read Code! (Jumping around the code):

```{r nested stryle, eval=TRUE, results='hide'}
summarise(
  group_by(
    mutate(
      select(
        filter(weather, origin=="EWR", year==2013, between(precip, 0.05, Inf))
      , origin:temp)
      , temp_square = temp^2)
    ,origin, month)
  , min(temp_square))
```

Can write commands in a natural order by using the `%>%` infix operator (which can be pronounced as pipe)

* By default the left-hand side will be piped in as the first argument of the function appearing on the right-hand side
* When the left-hand side is needed at a position other than the first, one can use the dot `.`, as placeholder

```{r dpylr pipe, results='hide', eval=TRUE}
weather %>% 
  filter(origin=="addEWR", year==2013, between(precip, 0.05, Inf)) %>%
  select(origin:temp) %>%
  mutate(temp_square = temp^2) %>%
  group_by(origin, month) %>%
  summarise(min(temp_square))
```

# Further useful functions in the tidyverse

## Get an overview of your data

```{r dplyr glimpse, results='hide', eval=TRUE, echo = TRUE}
#base R 
utils::str(iris)#Compactly Display the Structure of an Arbitrary R Object
#tibble version
tibble::glimpse(iris)#This makes it possible to see every column in a data frame.
```
## Combine multiple data frames

```{r dplyr combine, results='hide', eval=TRUE, echo = TRUE}
test_data_1 <- tibble(
    x = 1:5, 
    y = 1, 
    z = letters[1:5]
)
test_data_2 <- tibble(
  x = 1:8, 
  y = 1, 
  r = letters[1:8]
)
```
## Combine multiple data frames

```{r dplyr combine2, results='markup', eval=TRUE, error=TRUE, echo = TRUE}
#base R 
base::rbind(test_data_1, test_data_2)#Compactly Display the Structure of an Arbitrary R Object
#tibble version
dplyr::bind_rows(test_data_1, test_data_2)#This makes it possible to see every column in a data frame.
```

## Rename variable names

```{r rename, results='markup', eval=TRUE, error=TRUE, echo = TRUE}
rename(iris, petal_length = Petal.Length,
             sepal_length = Sepal.Length,
             petal_width = Petal.Width,
             sepal_width = Sepal.Width)
```
## Helper functions or `select()`
```{r select_helper, results='markup', eval=TRUE, error=TRUE, echo = TRUE}
select(iris, starts_with("Petal"))
select(iris, ends_with("Width"))
# Move Species variable to the front
select(iris, Species, everything())
# Drop variables with -
select(iris, -starts_with("Petal"))
```

## Operate on a selection of variables

The variants suffixed with `_if`, `_at` or `_all` apply an expression (sometimes several) to all variables within a specified subset. This subset can contain all variables (`_all` variants), a `vars()` selection (`_at` variants), or variables selected with a predicate (`_if` variants).

The verbs with scoped variants are:

* `mutate()`, `transmute()` and `summarise()`. See `summarise_all()`.
* `filter()`. See `filter_all()`.
* `group_by()`. See `group_by_all()`.
* `rename()` and `select()`. See `select_all()`.
* `arrange()`. See `arrange_all()`

```{r scoped, results='markup', eval=TRUE, error=TRUE, echo = TRUE}
mutate_if(.tbl = iris, .predicate = is.factor, .funs = as.character)
```

